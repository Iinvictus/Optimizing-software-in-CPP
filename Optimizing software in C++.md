

[TOC]



# C++程序性能优化

# Optimizing software in C++

An optimization guide for Windows, Linux, and Mac platforms

# 0. 前言

原文链接：https://www.agner.org/optimize/optimizing_cpp.pdf

# 1. 简介

该手册是写给高级程序员，以及那些想让软件运行得更快的开发者们。手册假定读者具备良好的C++编程知识，并对编译器的工作方式具有一定的了解。手册选择C++语言作为描述基础，原因在稍后（原文第8页）给出。

手册内容基于作者对编译器和微处理器工作机制的研究。给出的建议均基于`Intel`、`AMD`和`VIA`的x86处理器，包括64位版本。x86处理器广泛应用于`Windows`、`Linux`、`BSD`和`Mac OS X`操作系统。这些操作系统也可用于其他处理器和指令集。手册中的建议也同样适用于其它平台和编译语言。

本手册是五册系列手册的第一本：

1. Optimizing software in C++: An optimization guide for Windows, Linux, and Mac platforms.
2. Optimizing subroutines in assembly language: An optimization guide for x86 platforms.
3. The microarchitecture of Intel, AMD, and VIA CPUs: An optimization guide for assembly programmers and compiler makers.
4. Instruction tables: Lists of instruction latencies, throughputs and micro-operation breakdowns for Intel, AMD, and VIA CPUs.
5. Calling conventions for different C++ compilers and operating systems.

这些手册的最新版可以在 www.agner.org/optimize 访问到。相关版权条款再原文176页.

如仅需使用高级语言实现软件，只需阅读本手册。其它手册是为想更进一步深入研究：指令时序、汇编语言编程、编译器技术、微处理器的微架构 等技术细节提供。

请注意：全球有成千上万人使用优化系列手册。我个人没有时间回答所有人的问题。请不要发送你的程序问题，我不会回复这些提问。建议初学者在接触本系列手册之前，先拥有较好的编程经验。如果不能在相关书籍和手册中得到关于变成问题的解答，可以去一些论坛获取。

感谢那些对该系列手册提出建议和修正的人们，非常高兴能收到这些信息。

## 1.1 为什么软件常常很慢

近几十年，微处理器性能指数级的提升。但令人沮丧的是，仍然有很多软件的响应时间很长。通常情况下，软件性能问题的原因并不是糟糕的微处理器设计，而是糟糕的软件设计。罪魁祸首通常是及其浪费的软件开发工具、框架、虚拟机、脚本语言和多层抽象软件设计。根据摩尔定律，随着不断逼近物理极限，硬件性能的提升正逐步放缓。相反，`wirth`定律调侃道：当前软件性能下降的速度超过了硬件性能提升的速度。

在这样的处境下，软件开发者应注重提升软件性能，而不再是仅仅依赖硬件性能的提升。避免使用低性能的软件工具和框架，同时避免功能膨胀。如本手册所述：减少软件开发中的抽象层级，有助于理解不同代码结构的性能开销。

## 1.2 优化的代价

现今大学的计算机课程更强调一下问题的重要性：

- 数据结构和面向对象编程
- 模块化
- 重用性
- 多层抽象
- 系统化的软件开发流程

这些需求通常与软件运行速度和尺寸优化相互冲突。

现在，老师们长建议函数\方法的长度不应超过多少行。而在几十年前，这条建议恰恰相反：当一个函数仅被调用一次时，不要将其放入单独的子程序中。软件项目规模变大、复杂度变高，同时计算机性能的不同提高，使人们更加注重软件的开发、维护成本。正是这种变化，导致了软件开发风格的变化。

对结构化软件开发的重视和对软件性能的忽视，首先反映在编程语言和接口框架的选择上。这也导致，终端用户不得不升级他们的计算机，以满足日益庞大的软件包。同时，他们不得不面对较慢的响应时长，即使是在处理简单任务的时候。

有时，为了获取更强的软件性能和更小的尺寸，不得不在现今的软件开发原则上做出让步。本手册将讨论以下内容：

- 如何在这些影响因素间取得合理的平衡；
- 如何辨别、分离程序最关键的部分，并对其进行重点优化；
- 如何克服原始编程风格下的风险，比如：不自动检查数组越界、无效指针等；
- 从运行时间的角度看，高级编程结构的开销大小。

# 2. 选择最佳平台



## 2.1 硬件平台的选择

硬件平台的选择已经变得不如以前重要了。 因为`CISC`指令集的标准PC也包含了：`RISC`核心、向量处理指令集、多核心和远超此前大型机的处理器性能，`RISC`和`CISC`处理器、PC与大型机、简单处理器和向量处理器（`vector processors`）之间的差异变得越来越小。

现今，相较于硬件性能因素，硬件平台的选择更多取决于：价格、兼容性、第二供应来源、相应的开发工具等因素。相较于大型机，多台PC的组网也更加便宜、高效。有大规模并行计算能力的大型机在科学计算领域仍占据重要地位。但对通用目的而言，PC因其更高的性价比成为首选。

仅从技术角度看，标准PC处理器采用的`CISC`指令集不是最优选择。维护这一指令集的一大重要目的是兼容最早至1980年前后的一系列软件。在那时，RAM内存和硬盘空间均是稀缺资源。但是，`CISC`指令集也不想传说的那么糟糕。CPU缓存仍是稀缺资源，指令集的代码紧凑性使其具有更高的缓存效率。在代码缓存至关重要的情况下，`CISC`指令集实际要更优于`RISC`。`CISC`的另一优势是，执行相同的工作，它需要更少的指令。x86指令集的一个严重缺点是寄存器的稀缺。在64为扩展中寄存器数量增加了一倍，使这一问题得到了缓解。

不建议在关键应用中采用依赖网络的瘦客户端，因为网络资源的响应时间是不可控的。

小型便携型设备被越来越多的用于原来必须依赖PC才能完成的应用中，例如：电子邮件和网页浏览器。同时，更多的设备开始采用嵌入式微处理器。我并不对这类应用应该最优先采用哪些平台和操作系统给出建议。但必须认识到，这些设备通常比PC机拥有更少的内存和更弱的计算能力。但如原文169页所述，通过优化软件设计，许多应用在这些设备上依然可以取得不错的性能表现。

本手册基于配备Intel、AMD、VIA处理器的32位或64位`Windows`、`Linux`、`BSD`、`Mac`操作系统。手册中的很多建议也同样适用于其它平台，但这里例子仅在PC平台上进行了测试。

### 图形加速器

平台的选择势必与任务需求强相关。例如，重图形应用首选在有图形加速器或图形加速卡的平台上实现。一些系统甚至采用专门的物理处理器，计算游戏或动画中的物理运动。

在某些情况下，可以将图形加速卡用于非图形渲染的其它目的。但这类应用严重依赖于特定系统。当可移植性很重要的时候，不建议采用这类方式。本手册也不包含图形处理器的相关内容。

### 可编程逻辑器件

可编程逻辑器件是一种可以使用`VHDL`、`Verilog `等硬件定义语言编程的芯片。常用器件是`CPLDs`和`FPGAs`。不同于软件编程语言定义一系列指令构成的算法，硬件定义语言使用门电路、触发器、多路复用器、算术单元和连接线路定义硬件电路。因为硬件定义易语言定义电路而不是操作序列，所以其本质上是并行的。

由于可以为特定目的专门设计电路，可编程逻辑器件中的复杂数字操作通常比位处理器中执行得更快。

在`FPGA`中先实现微处理器也是可行的，即为所谓的额软处理器。这类软处理器比专用微处理器要慢很多，因此其并不具有优势。但在一些情况下，使用同一芯片下的软处理器处理特定的关键应用指令可能更为高效。一种更高效的方案是在同一块芯片上集成专用微处理器和`FPGA`。这类混合方案已经被用于一些嵌入式系统中了。

我认为，类似的方案此后也会在PC处理器上实现。应用程序将可以使用硬件定义语言定义一些专用指令。这种处理器在位代码和数据提供缓存之外，也会额外为硬件定义代码提供缓存。

## 2.2 微处理器的选择

由于激烈的竞争，不同微处理器间的性能测试十分接近。对可以分解在多线程中并行处理的应用来讲，多核处理器是十分有用的。对非计算密集的应用来讲，低功耗处理器非常合适。

## 2.3 操作系统的选择

新型x86微处理器都可以运行在16位、32位、64位模式下。

在`DOS`、`Windows 3.x`等旧操作系统都运行在16位模式下。如果程序或数据大小超过64k字节，系统就会使用内存分段。对较大的程序来讲，这种模式是非常低效的。现在微处理器并未对16位模式进行优化，一些操作系统也没有对16位做兼容。因此除小型嵌入式系统外，不建议开发16位程序。

64位操作系统现在很常见。这些系统可以运行32位和64位应用。对一些函数调用量大的CPU密集型程序和大量使用RAM内存的程序来讲，64位系统可以提升5%~10%左右的性能。如果系统瓶颈在其它地方，那32位和64位系统没有差别。大量使用内存的应用会受益于64位系统提供的更大的地址空间。

在`Windows`和`Linux`系统下，32位程序性能相差无几。因为两者使用相同的函数调用约定。手册中提到的`Linux`相关内容同样适用于`BSD`系统。

Intel处理器的`Mac OS X`系统基于`BSD`，但编译器默认使用位置无关代码和延迟绑定，所以性能较低。通过使用静态链接和不适用位置无关代码（使用`-fno-pic`选项）可以提高性能。

对比32位系统，64位系统有以下优势：

- 寄存器数量翻倍，这使将中间数据和局部变量存储在寄存器中成为可能。如果支持`AVX512`指令集，64位模式下向量寄存器尺寸会更大。
- 可以在寄存器中而不是栈上进行函数参数传递。这使参数调用更加高效。
- 整数寄存器尺寸扩展到64位，有利于应用程序使用63位整型。
- 大内存块的分配和释放更高效。
- 所有64位CPU和操作系统都支持SSE2指令集。
- 64位指令集支持数据的自相关寻址。这可以使与位置无关的代码更有效率。

对比32位系统，64位系统有以下劣势：

-  指针、引用、堆栈条目使用64位而不是32位。这会降低数据缓存的效率。
- 如果不能保证内存镜像基地址小于2^31，那么访问静态和全局数组需要额外的指令。
- 在代码和数据大小总和超过2GB时，地址计算会更复杂。
- 一些指令会比32位下长一个字节。

通常可以认为，当存在大量的函数调用、需要分配较大内存块或可利用64位整型计算时，64位程序略快于32位程序。当程序超过2GB大小后，则必须使用64位系统。

在64位下函数调用的约定不同，不同操作系统有所差异。64位`Windows`系统只允许在寄存器中传输4个参数，而64位`Linux`、`BSD`、`Mac`系统允许传递多达14个参数（6个整型、8个浮点型）。还有其它的一些细节使64位`Linux`系统比64位`Windows`系统更高效（参见：原文50页和手册5）。函数调用较多的程序在64位`Linux`上运行比64位`Windows`稍快。可以通过将关键函数内联或改为静态函数、使用进行整个程序优化的编译器改善64位`Windows`系统的这个缺点。

## 2.4 编程语言的选择

在开发一个软件之前，确定使用哪个编程语言实现最合适是至关重要的。采用低级语言有利于程序速度和程序大小的优化。而采用高级语言有助于代码清晰、结构良好，同时，可以快速的开发用户界面、网络资源、数据库等的接口。

最终程序的执行效率取决于编程语言的实现方式。将代码编译分发成二进制可执行代码可以获得最高的效率。`C++`、`Pascal`、`Fortran`这些语言都是基于编译器的。

也有一些基于解释器的编程语言。将代码原封不动的在运行时进行逐行解释，例如：`JavaScript`、`PHP`、`ASP`、`Unix shell`。因为循环中的代码会被一次次重复解释等原因，解释型代码非常低效。

还有一些代码使用即时编译技术（JIT）。源码被原样分发和保存，并在运行时进行编译，例如：`Perl`。

也有一些现代编程语言使用中间码（字节码）。将源代码编译成中间码，然后发布中间码。中间码不能直接运行，必须经过二次解释或者编译。一些基于解释器的`Java`实现，模拟`JVM`(Java虚拟机)来解释中间码。最好的采用`JIT`编译最常用的代码。微软`.NET`框架下的`C#`和其它语言都是基于中间码的即时编译技术。

中间码的优势是其平台无关性和紧凑性。中间码最大的缺点是，用户位运行程序必须安装一个很大的运行时框架来解释或编译中间码。这个框架通常要比应用程序本身占用更多资源。

中间码的另一个缺点是，它增加了一层额外的抽象。这使得细节优化更难进行。另一方面，即时编译器可以针对正在运行的CPU进行优化，但在预编译代码中针对CPU优化会更复杂。

编程语言及其实现展示了一个曲折的过程，这个过程反映了性能、平台无关性、易开发之间的权衡。比如，最早的PC机采用基于解释器的`Basic`。但因为解释版本的`Basic`效率太低，很快`Basic`的编译器就问世了。而现在，最主流的版本是`Visual Basic .NET`，使用中间码和`JIT`实现。`Pascal`的一些早期实现就像`Java`一样采用了中间码，但直到其编译器问世后，这一语言才真正流行起来。

从以上讨论中，可以明显看到：编程语言的原则是基于效率、可移植性、开发时间的平衡。当效率很重要是，就不会采用解释型语言。当可移植性和易开发性比较重要时，通常采用`C#`、`Visual Basic`、`Java` 这些基于中间码和`JIT`技术的语言。但是这类语言的缺点是，要运行程序必须加载庞大的运行时框架，而且加载框架和编译程序的时间通常远远多于执行程序的时间。运行时框架可能占用比程序本身更多的资源。对点击按钮、移动鼠标这类简单任务来讲，使用这类框架的响应时间通常难以接受。当速度非常关键时，就应该避免使用类似框架。

毫无疑问，使用`C`、`C++`、`D`、`Pascal`、`Fortran`这类完全编译的代码可以获得最快的执行效率。出于以下原因，作者个人更喜欢`C++`:

- `C++`有很多非常优秀的编译器和优化良好的函数库支持；
- 相较于其他语言，`C++`是一门拥有众多高级特性的高级语言；
- 同时，`C`语言还是`C++`的子集，支持进行一些底层优化；
- 大多数`C++`编译器都支持汇编代码，这对检查编译器如何进行小段代码优化非常有用；
- 当需要进行最高级别的优化时，大部分`C++`编译器支持类汇编函数、内联汇编 或轻松链接汇编模块；
- 因为`C++`编译器支持所有主流平台，`C++`是可移植的。

`Pascal`具有很多`C++`的优点，但并不全面。`Fortran`也相当高效，但其语法相当老套。

通过使用许多强大的开发工具，`C++`的开发效率相当高效。`Microsoft Visual Studio`就是其中一种很流行的开发工具。它可以生成直接编译的二进制可执行代码或者采用`.NET`框架的中间码。显然，当速度很重要时，应选择直接编译。

`C++`的一个明显缺点是其安全性，没有数组边界检查机制、整数溢出和无效指针。没有这些检查使其执行速度更快。但这就需要程序员在逻辑上无法排除这类错误的时候，对其进行显式检查。原文14页提供了一些相关建议。

毫无疑问，当性能优化很重要时，`C++`是首选语言。和其他语言相比，其性能可提升空间更大。当性能对终端用户至关重要时，为获取性能提升，增加一点开发时间是有意义的。

在某些场景下，由于一些原因必须采用基于中间码的高级框架，但其中的部分代码仍需要进行仔细优化。此时，混合实现是一个可行方案。使用`C++`实现一些关键代码，`UI`等其他部分可以使用高级框架实现。可以将优化部分编译为动态或者静态链接库，供其他代码调用。因为高级框架仍会占用大量资源，且两种代码间的转换会带来额外开销，所以这种混合实现并非最优解决方案。但是，当耗时的关键代码完全在动态或静态库中时，这种方案仍能极大提升性能。

## 2.5 编译器的选择

近几十年来，`C++`编译器变得越来越复杂。用于高级向量操作的`AVX512`指令集扩展，使现存数千种不同的机器指令。`C++`语言的一些高级特性也增加了其复杂度。市面上`C++`编译器的数量减少了，过去一些很流行的编译器，现在已经过时或者停止更新。作者猜想未来编译器的数量会进一步减少。

下面介绍一些`x86`和`x86-64`平台下的最佳编译器。这些编译器都支持32位、34位和自动向量化(`automatic vectorization`)。

- Microsoft Visual Studio

  这是个用户友好度极高的、拥有许多特性的编译器和调试器。它的完整版非常昂贵，但也提供功能有限的免费非商业版本。`VS`可以用于使用多种编程语言（`C++`、`C#`、`VB`）为多种平台构建代码。就代码优化而言，它不是最优的编译器。但其在项目的开发阶段非常有用。当代码性能很重要的时候，可以使用其他编译器生成代码的`release`版本。可将`VS IDE`与其他编译器搭配使用。

- Gnu

  `gcc or Gnu`编译器是最佳优化编译器之一。但其用户友好度弱于VS。在很多时候，必须花大力气才能搞懂需要编译选项。它是开源、免费的，并且支持几乎所有的平台。单独的编译器需用使用命令行运行，但`Eclipse`、`NetBeans`、`CodeBlocks`等一些编译器也集成了`gcc`。

- Clang

  `Clang`是一个非常好的优化编译器。在很多情况下，它甚至是最好的。`Clang`和`gcc`拥有几乎相同的特性和选项。它是`Mac`平台上最常用的编译器，它也同样支持`Linux`和`Windows`平台。`Clang`基于`LLVM`（`Low Level Virtual Machine`），但这额外的一层似乎不会影响性能。

  `Windows`平台下`Clang`有不同的版本。目前最好的版本是作为`VS`插件的16.2或更高版本。`VS`的`Clang`插件仅适用于`CMake`项目，但其承诺未来会支持普通`VS`项目。同时，仍可以通过命令行使用此编译器。

  `Cygwin64`版本的`Clang`默认使用中等内存模型。对静态变量和常量，它将使用64位绝对地址而非32位相对地址，这是非常浪费的。可以通过指定`-mcmodel=small`选项提高性能。只有需要直接链接外部动态库中的变量时（这是一种糟糕的编程实践），才需要使用中等内存模型。`Cygwin`版本的另一个缺点是，在分发可执行程序时，必须附带`Cygwin DLL`。

- Intel C++ compiler

  这个编译器没有自己的`IDE`。在`Windows`平台使用时，它作为`VS`中的一个插件；在`linux`平台使用时，它作为`Eclipse`的一个插件。也可以通过命令行单独使用。它支持`Windows`、`Linux`和采用`Intel`处理器的`Mac OS`和`Itanium`系统。

  这种编译器支持自动匹配CPU，会针对不同的`Intel`CPU生成不同的版本。它最主要的缺点是，针对特定型号的`Intel`CPU进行了优化。如果检测到其他品牌(`AMD`、`VIA`)的CPU，即便CPU支持最佳的代码分支，也仍会运行速度较慢的另一分支。在一些情况下，可以通过绕过检查是否运行在`Intel`CPU的代码来避免此问题。

  `Intel`编译器有一些其他编译器不具备的优化功能，但这些优化通常只会增加代码的复杂度，对性能几乎没有提升。

根据作者的测试，开源的`Clang`和`Gnu`编译器在代码优化方面是最好的。原文76页有针对上述四种编译器的详细测试。

所有的编译器都可以在命令行模式运行。商业编译器也提供免费试用版。

如果不同编译器的产物是为同一平台编译的，通常情况下，混合使用这些产物没有什么问题。`Intel`和其它`VS`、`Gnu`编译产物的兼容性，取决于平台。`Gnu`和`Clang`的编译产物是相互兼容的。其它编译器组合要求声明`extern C`。一些较久的编译器和上述编译器不兼容。

在某些情况下，编译器的选择可能取决于历史代码的兼容性、特定的IDE设定、调试设施、是否已于GUI开发、数据库集成、web应用集成、混合语言编程等因素。当特定编译器不能达到性能需求时，对不同关键模块采用不同编译器编译是一个可行的解决方案。如果主项目使用不同的编程语言开发，需要将优化的`C++`代码编译为动态链接库，否则首选静态链接库。

## 2.6 函数库的选择

一些应用大部分运行时间都是在运行库函数。耗时的库函数通常属于以下几种情况：

- 文件I/O
- 图形和声音处理
- 内存和字符串操作
- 数学函数
- 加解密和数据压缩

大部分编译器都包含这些标准库。但不幸的是，标准库并不总是完全优化的。

很多应用中使用库函数作为程序中的小块代码。因此，比起优化应用程序特定的代码，更值得在优化库函数上投入更多精力。最好的库函数都是经过 使用汇编语言和基于最新指令集的自动CPU调度（automatic CPU-dispatching，见原文131页）高度优化的。

如果分析显式某一应用的库函数调用占用了大量时间，那么可能通过使用不同的函数库来显著提升程序性能。如果应用程序在库函数上消耗了大量时间，那除了找到最高效的函数库、减少库函数调用消耗外，可能无需进行如何优化。建议尝试不同的函数库，选择其中最优的。

下面列出了一些常用的函数库，包括一些用于特殊用途的：

- Microsoft

  `Microsoft`编译器附带的，其中一些函数优化的很好，也有一些函数不尽人意。支持32位和64位`Window`。

- Gnu

  `Gnu`编译器附带的。64位版本优于32位版本。相比常见的用户函数，`Gnu`编译器常常使用内置函数。但内置函数并不总是最优的。可以通过`-fno-builtin`指令来指定使用用户函数。`Gnu`库支持32位和64位的`Linux`和`BSD`系统。

- Mac

  `Gnu`编译器附带的给`Mac OS X`的库，是`Xnu`项目的一部分。一些重要的函数包含在所谓`commpage`的操作系统内核中。这些函数针对`Intel Core`和更新版本的`Intel`处理器进行了高度优化。不适用于`AMD`和老版本的`Intel`处理器，且仅适用于`Mac`平台。

- Intel

  `Intel`编译器附带的标准函数库。还提供了`Intel Math Kernel Library`、`Integrated Performance Primitives`等一些特殊用途的库。这些库函数针对大数据集进行了高度优化。然而，`Intel`库在`AMD`和`VIA`处理器上并不总能正常运行。原文139页说明了原因和可能的解决方法。支持所有的`x86`和`x86-64`平台。

- AMD

  `AMD core Math`库包含一些经过优化过的数学函数，同样适用于`Intel`处理器。但其性能不如`Intel`库。支持64位`Linux`。

- Asmlib

  作者维护的用于演示目的的库。可通过 www.agner.org/optimize/asmlib.zip 获取。目前包含一些内存和字符串函数的优化版本，以及一些在别处难以找到的函数。在最新的处理器上运行时，优于大多数其它库。支持所有的`x86`和`x86-64`平台。

- 函数库对比

  | 测试项目                             | 处理器         | Microsoft | CodeGear | Intel | Mac  | Gnu 32-bit | Gnu 32-bit -fno-builtin | Gnu 64 bit fno-builtin | Asmlib |
  | ------------------------------------ | -------------- | --------- | -------- | ----- | ---- | ---------- | ----------------------- | ---------------------- | ------ |
  | memcpy 16kB aligned operands（对齐） | Intel Core 2   | 0.12      | 0.18     | 0.12  | 0.11 | 0.18       | 0.18                    | 0.18                   | 0.11   |
  | memcpy 16kB unaligned op.（非对齐）  | Intel Core 2   | 0.63      | 0.75     | 0.18  | 0.11 | 1.21       | 0.57                    | 0.44                   | 0.12   |
  | memcpy 16kB aligned operands         | AMD Opteron K8 | 0.24      | 0.25     | 0.24  | n.a. | 1.00       | 0.25                    | 0.28                   | 0.22   |
  | memcpy 16kB unaligned op.            | AMD Opteron K8 | 0.38      | 0.44     | 0.40  | n.a. | 1.00       | 0.35                    | 0.29                   | 0.28   |
  | strlen 128 bytes                     | Intel Core 2   | 0.77      | 0.89     | 0.40  | 0.30 | 4.5        | 0.82                    | 0.59                   | 0.27   |
  | strlen 128 bytes                     | AMD Opteron K8 | 1.09      | 1.25     | 1.61  | n.a. | 2.23       | 0.95                    | 0.6                    | 1.19   |

  表中的数字是操作每字节数据的核心时钟周期数（数字越小表示性能越好）。对齐的操作数意味着源地址和目标地址都可被16整除。

  被测试库并非最新版本：

  - Microsoft Visual studio 2008, v. 9.0 
  - CodeGear Borland bcc, v. 5.5 
  - Mac: Darwin8 g++ v 4.0.1. 
  - Gnu: Glibc v. 2.7, 2.8. 
  - Asmlib: v. 2.00. 
  - Intel C++ compiler, v. 10.1.020. Functions _intel_fast_memcpy and __intel_new_strlen in library libircmt.lib. Function names are undocumented

## 2.7 UI框架的选择

典型项目中的大部分代码都服务于UI。非计算密集型应用在UI上花费的CPU时间要远高于应用的根本任务。

程序员很少从头开始编写自己的UI界面。这不仅浪费程序员的时间，对终端用户来讲也很不方便。出于可用性考虑，菜单、按钮、对话框等组件应该可能标准化。程序员应该尽量使用操作系统自带的或者库提供的UI组件。

`Windows`和`C++`开发中流行的UI库是`MFC`。`Linux`有多种UI框架。UI库可以是静态或者动态库。除非多个应用共用一个动态库，动态库通常比静态库占用更多的内存。

UI库通常比应用程序本身大，且需要更多时间进行加载。一个轻量级的选择是`WTL` (`Windows Template Library`)。`WTL`应用通常比`MFC`应用更快、更紧凑。但由于缺乏文档和相关开发工具，其通常需要更长的开发时间。

有一些跨平台的UI库，比如：`Qt`和`wxWidgets`。对需要在多个平台和操作系统上运行的应用来说，它们更优。

最简单的UI就是，去掉图形界面使用控制台模式代替。控制台模式的输入通常在命令行或输入文件中指定。输出也在控制台或输出文件。控制台程序更高效、紧凑、易开发。因为不依赖于图形界面，可以很容易的一直到不同平台。但因为缺少图形界面的自解释菜单，其易用性不好。控制台程序非常适合仅需被其它程序调用的场景。

选择UI框架必须权衡：开发时间、易用性、程序紧凑型和执行时间这些因素。不存在一个通用的完美方案。

## 2.8 克服C++语言的缺陷

虽然`C++`在优化方面有诸多优点，但也存在一些缺点。本节讨论如何克服这些缺点。

- 可移植性

  从语法角度看，`C++`是完全规范化且支持所有主流平台的。但因为`C++`是一门允许直接访问硬件接口和系统调用的语言，而这些都于系统相关。为便于平台之间的移植，建议将UI和其它与系统相关的部分放在单独的模块，将与平台无关的应用本质代码放在另一个模块。

  整型大小及其它硬件相关的细节取决于硬件平台和操作系统。详见原文29页.

- 开发时间

  许多开发者认为使用特定的编程语言和开发工具可以取得更快的开发效率。通过使用加强的开发工具将许多琐碎工作自动化确实可以提高效率，但很多情况下，开发速度的差异源于习惯问题。通过持续的模块化和可重用类，可大幅提高`C++`程序的开发维护效率。

- 安全性

  `C++`语言最严重的问题就是其安全性。标准`C++`实现并不进行数组边界和无效指针检查。这是`C++`程序的常见错误来源，也是骇客可能的攻击点。有必要遵循一些编码规范，来避免安全敏感的程序中出现此类错误。

  无效指针可以通过以下方法避免：

  - 使用引用替代指针
  - 将指针初始化为零
  - 一旦指针指向的对象失效，将指针设为零
  - 避免指针算数运算和类型转换
  - 如原文95页所述，可使用更高效的容器类模板替代链表和其它使用指针的数据结构
  - 避免使用`scanf`

  违反数组边界是最常见的错误原因之一。在超出数组末尾的地址写入可能会覆盖其他变量，更严重的是，可能会覆盖定义此数组的函数的返回地址。这会导致各种各样奇怪的未定义行为。通常使用数组作为存储文本或其它数据类型的缓冲区。骇客经常利用缺少对输入数据缓冲区溢出校验实施攻击。

  避免此类错误的常见方法是：用经过重复测试的容器类替换数组。但不幸的是，`STL`作为此类容器库的重要来源，其中的许多容器类以低效的方式使用动态内存分配。原文92页描述了如何避免动态内存分配。原文95页讨论了高效容器类。手册附件 www.agner.org/optimize/cppexamples.zip 中包含了进行边界检查和高效容器类的示例。

  因为缺乏对字符串长度的限制，文本字符串很容易引发问题。`C`风格代码使用`char`数组存储字符串是快速高效的。但存储前不经长度校验是十分危险的。这个问题的标准解法是使用`string`、`CString`这样的字符串类代替。这样可以保证安全灵活，但在大型应用中效率很低。每次字符串创建或修改时都需要分配一块新内存。这将导致内存碎片化，造成严重的推内存管理和垃圾回收开销。一种更有效的不影响安全性的方案是：将所有字符串存储在一块内存池中。手册附件 www.agner.org/optimize/cppexamples.zip 中演示了如何在内存池中存储字节串。

  另一个安全问题是整数溢出。官方`C`标准指出：有符号整型的溢出是未定义的。这就允许编译器忽略溢出或者假定不会发成溢出。在`Gnu`编译器下，不会出现有符号整型溢出的假设，会引发不好的后果，即编译器可能优化、移除掉溢出检查。针对此问题可以通过以下方法补救：

  - 在溢出发生之前进行溢出检查
  - 使用无符号整型，他们会保证环绕（最大值+1取模）
  - 使用`-ftrapv`捕获整型溢出，但这样效率极低
  - 启动`-Wstrict overflow=2`选项打开编译器警告，以便进行优化
  - 使用`-fwrapv`或`-fno-strict-overflow`选项，定义良好的溢出行为。

  当性能至关重要时，可能会偏离上述安全建议。如果不安全代码仅限于经过良好测试的函数、类、模板 或者 定义良好的模块，那这种取舍是可以接受的。

# 3. 找最大的时间开销

## 3.1 一个时钟周期是多久？

因为计算机的速度差异相当大，所以在本手册中，作者使用CPU时钟周期而不是秒、微妙作为时间尺度。如果现在一个任务的耗时需要10us，很可能在下一代计算机上仅需5us。但如果使用时钟周期度量，即使CPU时钟频率加倍，在下一代计算机上仍需相同的时钟周期。

时钟周期的长度是时钟频率的倒数。假设时钟频率是4GHz，则时钟周期长度为`1/4GHz = 0.25ns`。

假设程序中一个循环重复1000次，每次循环执行100个浮点运算。如果每次浮点操作需要5个时钟周期，粗略估计在4GHz CPU上，循环整体耗时 `1000 * 100 * 5 * 0.25ns = 125us`。显然此时无需对这个循环做优化，125us比屏幕刷新一帧时间的1%还要少。用户感知不到这样的耗时。但假设在另一个循环中，这个125us的运算要进行1000次，耗时预计125ms，此时延迟就已经长到足够引起注意，但并非不可接受。可以大概以125ms为基准进行测试，如果响应时间太长，用户不得不进行有感知的等待时，需要考虑是否能够进行一些优化。

## 3.2 使用分析器查找热点

在进行任何优化前，都必须明确程序的核心部分。一些程序花费99%的时间在数学计算上，还有一些程序99%的时间与来读取和写入文件，实际处理数据的时间不到1%。优化重要的代码，而不是只占用小部分时间的代码。优化代码中不太关键的部分不但会浪费开发时间，还会使代码变得不那么清晰，难以调试和维护。

大多数编译器都附带一个分析器，它能告诉你每个函数被调用次数和时间。也有一些第三方分析器，比如`AQtime`、`Intel VTune`和`AMD CodeAnalyst`。

性能分析方法包括以下几种：

- 插桩（Instrumentation）：编译器在每次函数调用时插入额外代码，来统计函数被调用次数和所需时间。
- 调试（Debugging）：分析器在每个函数或代码行插入临时断点。
- 基于时间的采样：分析器告知系统以特定频率产生中断，比如，每毫秒一次。然后统计分析中断在程序各个部分发生的频率。无需修改被测程序，但可靠性较低。
- 易于事件的采样：分析器告知CPU在特定事件发生时生成中断，比如，每发生1000次缓存未命中。这样可以查看程序的哪些部分引发醉倒的缓存未命中、分支预测错误、浮点异常等。基于事件采样需要特定的CPU分析器支持。在`Intel`CPU上需要使用`VTune`，在`AMD`CPU上需要使用`CodeAnalyst`。

但不幸的是，分析器往往不可靠。因为一些技术原因，它们有时会给出误导性的结论，甚至完全失败。分析器的一些常见问题如下：

- 粗粒度的时间测量。假设以毫秒分辨率来测量时间，但关键函数的执行时间为微秒级，那么测量结果就会不精确甚至为0；
- 执行时间过长或过短。时间过短，则生成的数据不足以进行分析。时间过长，则有可能处理不了这么大量的数据。
- 等待用户输入。许多生成花费大量时间等待用户输入或者网络资源。这些时间同样会被分析器采集到。可能需要对测试程序进行改造，使用特定测试数据代替用户输入，才能进行分析。
- 来自其它程序的干扰。分析器不仅测量被测程序的运行时间，也会测量同一台计算机上运行的其它进程（包括分析器本身）
- 高度优化后的函数地址被隐藏。分析器通过函数地址，将函数地址转化为函数名来分析程序中的热点。但经过高度优化后的程序，函数地址和函数名常常没有明确的对应关系。对分析器来讲，内联函数的函数名可能根本不可见。这会导致产生误导性的分析结果。
- 使用`debug`版的代码。一些分析器要求被测代码包含调试信息，以便识别单个函数或者代码行。但代码的`debug`版是未经(编译器)优化的。
- 在CPU核心间跳转。进程或线程并不一定会一直在同一个CPU核心上运行，但事件计数器会。这将导致在多个核心上跳转的线程的无意义的事件计数。需要设置线程关联掩码（`thread affinity mask`）将线程绑定到特定核心上。
- 可浮现性差。程序的执行演示可能由偶先的随机事件引起。比如，任务切换和垃圾回收等事件可能在任意时间发生，并使程序的某一部分执行时间长于正常水平。

除使用分析器以外，还由一些其它的替代方法。一个简单的方法就是咋调试器中运行程序，并在运行中中断。如果有一个热点占用了90%的运行时间，那么有90%的几率会在这个热点处中断。重复进行几次中断就可能确定热点。再使用调试器中的调用堆栈来查看热点附件的情况。

一些情况下，比起使用现成的分析器，测试程序性能瓶颈的最佳方式是将测试代码嵌入到被测代码中。这种方法不能满足性能分析的全部需求，但通常能提供更可靠的测试结果。如果对分析器的工作方式不满意，可以将测试代码嵌入被测程序中。可以添加计数变量统计函数被调用次数。可以通过代码区间开始和结束时间来计算代码运行时间。原文164页有对这一方法的详细描述。

需要在测试代码前后加入`#if`指令，以便在最终版本中禁用这些代码。将测试代码嵌入被测代码中，可以在开发过程中方便的跟踪程序性能。

如果运行时间很短，时间测试就需要很高的分辨率。在`Windows`中可以使用`GetTickCount`或者`QueryPerformanceCounter`函数获取毫秒级的分辨率。使用CPU中的时间戳计数器可以获取更高的分辨率，该计数器以CPU时钟频率。在`Windows`中，通过`__rdtsc()`获取。

当线程在CPU多核之间跳转，则CPU时间戳计数器就会失效。如需使用，需要将线程绑定到特定CPU核心，在`Windows`平台，通过`SetThreadAffinityMask`，在`Linux`下，通过`sched_setaffinity`。

应该使用一组真实数据对程序进行性能测试。测试数据应该具有随机性，以便获取真实的缓存未命中和分支预测错误计数。

发现程序中最耗时的部分后，就可集中精力对耗时部分进行优化。原文164页描述了进一步测试、探查关键代码段的方法。

分析器对分析CPU密集型应用最有效。但很多程序花费大量时间在文件加载、数据库访问、网络资源访问。以下部分将讨论常见的耗时操作。

## 3.3 程序安装

传统意义上，不将程序安装时间列入软件优化问题中。但这一过程肯定需要消耗时间。如果认为软件优化的目的是为用户节省时间的话，那这一过程就不该被忽视。由于现代软件的高度复杂性，安装过程花费超过一小时的例子并不少见。而且为查找和解决兼容性问题，用户可能需要进行多次重新安装。

在决定使用需要安装很多文件的复杂框架前，软件开发人员需要将安装时间和兼容性问题考虑在内。

安装过程应该使用标准化的安装工具。并允许用户在安装前选择安装选项，一边剩下的安装过程可以在无人看管的情况下持续进行。同样，卸载也应该以标准化的方式进行。

## 3.4 自动升级

很多软件定期通过互联网自动下载更新。有些在开机后自动检查更新，即使软件从未被使用。安装了很多此类程序的计算机，需要花费很长时间才能完成启动，这完全是在浪费用户的时间。还有一些程序会在程序启动时检查更新。即使当前版版本满足用户需求，无需进行更新。除非有重要的安全更新，更新检查应该时可选、默认关闭的。更新进程应该在低优先级线程中运行，并只应该在程序运行时进行。当程序不再运行时，更新程序不应在后台运行。已经下载好的更新，应该延迟代程序关系并重启。

操作系统更新可能特别耗时，有时甚至需要花费数小时。如果这类更新进行的时间是不可预测的，或可能在方便的时间进行，是非常不妥当的。如果出于安全原因，用户在离开工作场所后必须关闭电脑，但系统禁止在更新过程中关闭电脑，也可能带来严重的问题。

## 3.5 程序加载

加载程序通常比程序运行花费更长的时间。对基于大型运行时框架、中间码、解释器、即时编译器等组件的程序来说，加载时间可能长的离谱。`Java`、`C#`、`VB`这类语言编写的程序常常如此。

即使是采用`C++`编译实现的程序，程序加载也可能花费很多时间。当程序中使用了很多`DLL`、资源文件、配置文件、帮助文件和数据库时，通常会出现这种情况。操作系统在大型程序启动时，不会加载程序的所有模块，很多模块只有当用到时才会加载，或者当RAM空间不足时，一些模块会被交换到硬盘中。

用户希望按键、鼠标移动等简单操作可以得到即时相应。因模块或资源加载产生长达数秒的延迟，是不可接受的。吃内存的程序会迫使操作系统交换内存和磁盘空间，而这是简单操作高延迟的常见原因。

避免磁盘中散布过多的`DLL`、配置文件、资源文件、帮助文件。尽量减少文件数目，并将其存放在可执行文件同目录下。

## 3.6 动态链接库和位置无关代码

函数库可以编译为静态库或者动态库。因为一些原因，动态库要比静态库慢。原文155页详细解释了这些原因。

在类`Unix`系统中，通常在动态连接库中使用位置无关代码。默认情况下，`Mac`系统在任何使用都使用位置无关代码。位置无关代码效率较低，尤其实在32位下。原文155页解释了其低效的原因。

## 3.7 文件访问

读写硬盘上的文件通常要比处理文件中的数据花费更多的时间。特别当是一些病毒扫描软件，需要扫描所有的文件时。

顺序向前访问文件比随机访问要快，读写大快数据要比一次读写一点点要快。不要一次只读写少于几千字节的数据。

可以将整个文件镜像到内存缓冲区中，并在一次操作中进行读写，而不是非顺序的每次读写一点点。

访问最近访问过的文件要比从未访问过的文件快得多。这是因为该文件已经被拷贝到磁盘缓存了。

远程文件或者可移动磁盘上的文件可能不会被缓存。这可能会导致戏剧性的结果。作者曾经写过一个程序，通过调用`WritePrivateProfileString`（没写入一行内容就需要打开关闭文件一次）创建一个文件。因为磁盘缓存，这个程序在磁盘上运行的非常快，但却花费了好几分钟才将文件写入软盘。

对包含数值数据的大文件来说，使用二进制格式要比`ASCII`格式更紧凑、高效。二进制格式的缺点是：不是人类可读的，并且由于大小端存储方式的问题，不易移植。

在包含很多文件I/O操作的应用中，优化文件访问要比优化CPU使用更重要。如果在等待IO的时候可以进行其它CPU运行，那将文件访问放在单独的线程中可以起到优化的效果。

## 3.8 系统数据库

在`Windows`上访问系统数据库可能需要数秒时间。将应用程序的信息存储在单独的文件中可能要比存放在`Windows`系统中的大型注册数据库更有效。需要注意的是：如果使用`GetPrivateProfileString `、`WritePrivateProfileString `这样的函数读写配置文件(`.ini`文件)，系统可能将信息存储在系统数据库中。

## 3.9 其它数据库

许多应用程序使用数据库保存用户数据。数据库会消耗大量的CPU、内存、磁盘资源。简单场景下，可以使用`plain old data`文件代替数据库。数据库查询通常可以通过使用索引、使用集合(`set`)代替循环来进行优化。本手册不包含数据库优化的内容，但数据库优化是一种很重要且有效的优化方式。

## 3.10 图形

图形界面需要占用大量的计算资源。通常需要使用一个特定的图形框架。操作系统可能在其API中提供这样的框架。在一些情况下，操作系统API和应用程序之间还存在一层额外的第三方图形框架。这种额外的图形框架会额外消耗大量的资源。

应用程序中的每一个图形操作都通过调用系统API或图形库实现，这些API和库再去调用硬件驱动。调用图形函数非常耗时，是因为要经过层层调用、切换到保护模式再切换回去。显然，通过一次调用绘制多边形或`bitmap`，要比多次调用，每次绘制一个像素或一条线段要高效的多。

游戏和动画中的图形计算也需要消耗大量的实践，尤其是在没有图形处理单元的时候。

各种图形函数库和驱动性能差距很大。作者不能给出哪个最好的建议。

## 3.11 其它系统资源

对打印机或其他设备的读写最好是每次一大块而不是小块进行，因为每次调用驱动程序，都涉及到保护模式和正常模式的切换。

访问系统设备、使用操作系统的高级设施可能会很耗时。因为这可能涉及加载多个驱动、配置文件和系统模块。

## 3.12 网络访问

一些程序需要访问互联网或内网来进行自动更新、远程帮助文件和数据库访问等操作。网络访问的问题在于时间不可控。在测试时，网络访问可能很快，但在实际使用中，由于网络过载或离服务器较远，网络访问可能很慢甚至不可用。

决定使用本地或远程存储帮助文件和其他资源时，应将这个问题考虑在内。如果需要频繁更新，最好在本地镜像远程数据。

访问远程数据库通产需要使用密码登录。众所周知，登录是一个很烦人的耗时过程，尤其是在网络或数据库负载过重时，登录过程可能超过一分钟。

## 3.13 内存访问

与处理数据相比，从内存中读取数据可能需要花费相当长的时间。正因如此，所有现代计算器都有内存缓存。通常CPU有8~64K字节的一级缓存、256K~2M字节的二级缓存，通常还有一个数M字节的三级缓存。

如果程序中的数据多于二级缓存大小，并且分散在内存中，或者以非顺序方式访问，那内存访问可能是程序中最耗时的操作。如果缓存命中，读写内存中的变量只需2~4个时钟周期，否则，需要数百个时钟周期。原文25页介绍了数据存储，89页介绍了内存缓存。

## 3.14 上下文切换

上下文切换指：

- 多任务场景下，不同任务之间的切换
- 多线程应用中，不同线程之间的切换
- 或大型程序中，不同部分之间的切换

因为数据缓存、代码缓存、分支目标缓冲区、分支模式历史记录等内容可能必须更新，所以频繁的上下文切换会降低性能。

如果分配给每个任务或线程的时间片较小，上下文切换会更加频繁。时间片的尺寸由操作系统而非应用程序决定。

在具有多个CPU或多核心CPU的计算机上，上下文切换会少一些。

## 3.15 依赖关系链

现在微处理器可以乱序执行。这意味着，如果程序指定先计算a，然后计算b，并且a的计算会很慢。那处理器可以在a计算完成前开始b的计算。显然，只有在a、b相互独立时才能如此执行。

为利用无需执行，必须避免长的依赖链。依赖链指一系列计算，其中每个计算取决于前一个计算的结果。依赖关系链会阻止CPU同时进行多个计算和乱序执行。原文110页有断开依赖关系链的示例。

## 3.16 执行单元吞吐量

执行单元的延迟和吞吐量间有重要区别。例如，现代CPU需花费3~5个时钟周期进行浮点加法。但是每个时钟周期可以启动1~2个新的浮点加法。这意味着，如果每个加法依赖前面加法的结果，那么每3个时钟周期只能执行一个加法。但如果相互独立，那么每个时钟周期可以执行一两次加法。

计算密集型程序要取得最佳性能，需要满足：上文中提到的耗时操作不占主要地位、没有长依赖关系链。这种情况下，性能受执行单元吞吐量，而非延迟或内存访问的限制。

现代微处理器的执行核心分为几个执行单元。通常。有两个或多个整数单元、一个或两个浮点加法单元、一个或两个浮点乘法单元。这意味着可以同时进行整数加法、浮点加法、浮点乘法计算。

因此，执行浮点计算的代码，最好能平衡加法和乘法。减法和加法使用相同的计算单元，除法则会耗费更长的时间。在浮点运算间进行整数运算不会降低性能，这是因为整数运算采用不同的计算单元。比如，在执行浮点运算的循环中使用整型来计数、比较等。大多数情况下，可以认为这类整型运算不会增加总计算时间。

# 4. 性能与易用性



性能更好的产品可以为用户节约时间。对很多用户而言，时间是宝贵的资源。却在一些速度慢、难以使用、兼容性差、易出错的软件上浪费很多时间。这些问题都是可用性的问题，作者认为应该从可用性的角度看待性能问题。

这不是一本关于可用性的手册，但作者认为有必要在这里提醒程序员注意一些妨碍有效使用软件的障碍。在作者的免费电子书 http://en.wikibooks.org/wiki/Usability_for_Nerds 中有对这一问题的详细描述。

下面列出了一些造成用户时间浪费的典型原因和软件开发者应该注意的重要可用性问题：

- 大型运行时框架。`.NET`框架和`JVM`通常比应用程序占用的资源多。这些框架是资源问题和兼容性问题的常见根源，而且在安装框架、安装程序、程序启动、程序运行整个流程中，都造成了极大的耗时。使用这类框架的主要原因是可移植性，但其跨平台兼容性并不如预期那样好。作者相信，通过更好的编程语言、操作系统、API的标准化，可以高效的实现可移植性。
- 内存交换。软件开发人员的计算机通常比终端用户配置更高、拥有更多的内存。因此，开发人员可能忽视了过度的内存交换和其它资源问题，而导开发出的“吃资源”的应用在用户使用时表现不佳。
- 安装问题。程序的安装、卸载应该标准化，并且由操作系统而非特定安装工具完成。
- 自动更新。如果网络不稳定或者新版应用存在问题，那自动更新可能会引发问题。更新机制常常使用弹窗打断用户，告知其进行重要更新安装，甚至在用户专注其它工作时告知其重启电脑。更新机制不应该打断用户，而是通过图标提示用户有更新可用。或在程序重启时自动更新。软件经销商常常滥更新机制宣传其新本版本软件。对用户而言，这种行为很烦人。
- 兼容性问题。所有软件都应该在不同的平台、不同的屏幕分辨率、不同的系统色彩设置、不同的用户访问权限下测试。软件应该使用标准的API调用。而非自定义的`hack`和直接访问硬件。使用标准协议和标准文件格式。`web`系统需要在不同的浏览器、不同平台、不同屏幕分辨率下测试。应该遵守`Accessibility guidelines`.
- 拷贝保护。一些拷贝保护方案基于违反或规避操作系统标准的`hack`行为。这样的机制通常会引起兼容性问题和系统故障。许多拷贝保护方案基于硬件标识。这种方案在硬件更新时会出现问题。大多数拷贝保护机制都人用户很恼火，它会妨碍合法的拷贝，且不能阻止非法的拷贝。拷贝保护方案考虑到软件可用性问题。
- 硬件更新。变更硬盘或其他硬件通常导致重新安装所有软件，且丢失了所有的用户设置。重新安装工作通常需要一个工作日甚至更长时间。很多软件应该有更好的备份功能，而操作系统则应该更好的支持硬件拷贝。
- 安全。易受到网络病毒攻击和其它滥用的应用程序，会使用户付出极大的代价。而防火墙、病毒扫描程序和其它防护手段是兼容新问题和系统崩溃的最常见原因。此外，病毒扫描软件通常要占用很多的计算机资源。操作系统本身的安全软件通常要比第三方安全软件更可靠。
- 后台服务。很多后台服务对用户来讲不是必须的，完全是对资源的浪费。应考虑仅在用户主动激活时才运行服务。
- 功能膨胀。由于市场原因，软件通常会在每个新版本中添加新功能。这可能会导致软件占用更多资源、运行速度变慢，即便用户可能根本不使用这些功能。
- 认真对待用户反馈。用户投诉应该被视为bug、兼容性问题、可用性问题、期望新特性的重要信息来源。应该系统的处理用户反馈，确保这些信息被合理使用。应该明确、及时回复用户问题调查结果和计划解决方案。补丁程序应该便捷的通过网站获取。

# 5. 选择最佳算法

优化CPU密集型应用，首先要做的是找到最佳算法。对排序、搜索、数据计算等任务来讲，选择算法是至关重要的。在这种情况下，最佳算法通常比首先想到的算法性能高很多。可能需要测试不同的算法来找出最佳算法。

话虽如此，但必须警惕过度优化。如果简单算法可以足够快的完成任务，就不要使用先进但复杂的算法。比如，一些程序员对很小的数据集使用哈希表。对非常大的数据库来讲，哈希表可以显著缩短搜索时间。但对使用二分查找甚至线性查找已经足够快的小数据集，没有理由使用哈希表，哈希表会增加代码和数据文件的大小。如果系统瓶颈是文件访问或缓存访问，而非CPU，这种改进实际会降低性能。复杂算法的另一缺点是：会是程序开发更困难、更易出错。

本手册不讨论针对不同目的的不同算法之间的差异。可查阅算法和数据结构相关文献或特定讨论复杂数学算法的文献。

在开始编码以前，需要考虑前人是否已经完成过这项工作。很多标准库中都包含可解决一些标准任务的经过良好优化的代码。例如，`boost`中包含很多经过良好测试的通用算法，`Intel Math Kernel Library`中包含很多线性代数、统计等常见的数学计算函数，`Intel Performance Primitives`中包含很多用于音视频处理、信号处理、数据压缩、加解密函数。如原文139页所述，如需使用`Intel`库，需要确保它在非`intel`处理器上正常运行。

在刚开始编程时就确定最佳算法是很难做到的。很多时候，只有在将整个项目整合在一起并进行测试后，才找到更好的算法。通过测试和分析程序性能瓶颈，可以更好的理解问题。这些新的更深刻的理解甚至可能引起对软件的重新设计，比如，当你发现可以使用更好的方式组织数据时。

对一个已经可以正常运行的程序进行重新设计必然是一项相当大的工程，但这可能是值得的。重新设计不仅可以提升程序性能，还可以使程序结构更清新，更容易维护。 实际上，重新设计通常要比解决原有框架的问题花费的时间更少。

# 6.开发流程

针对采用和汇总开发流程和原则，一直饱受争论。手册中不推荐特定的开发流程，相反，会解释开发流程会如何对最终的程序性能产生影响。

为预测哪些资源可能成为瓶颈，在计划阶段对数据结构、数据流、算法进行深入分析是十分重要的。然而，在开始阶段有太多的未知因素、考虑不到的因素，在此阶段很难对问题进行详细的分析。在复杂场景下，只有在开发阶段中后期才能对问题有充分理解。在这种情况下，需要将软件开发过程视作一个学习的过程，通过测试反馈问题信息、指导开发。此时，需要准备好不断迭代、重新设计。

一些软件开发模型有严格的形式要求，需要在逻辑上将软件分为不同的抽象层。应该认识到这种形式化是有成本的。软件分层过多是性能下降的常见原因。

大多数开发方法本质上都是增量、迭代的。因此，一套保存各个中间版本备份的机制是十分重要的。建议使用适当的版本控制工具。

# 7. 不同C++组件的性能差异

大多数程序员都不清楚一段源代码如何被翻译成机器码，以及微处理器如何执行这些代码的。例如，很多程序员不知道双精度浮点计算和单精度一样快，模板类比多态类更高效。

本章旨在解释不同C++组件之间的效率差异，以帮助程序员选择最佳方案。相关的理论背景在其它手册中进行了解释。

## 7.1 不同类型的变量存储

`C++`程序中变量和对象在内存中的存储位置，取决于声明的方式。这会影响数据缓存的效率。如果数据随机分散在内存中，则数据缓存效率很差。因此了解变量的存储方式非常重要。简单变量、数组、复杂对象的存储规则是相同的。

栈存储

除以下各节中描述的情况外，在函数中声明的变量和对象均存储在栈上。

栈是内存的一部分，以先进先出的方式组织。栈用于保存函数返回地址（即调用函数的位置）、函数参数、局部变量和函数返回前必须恢复的寄存器。每次函数调用时，都会在栈上为上述目的分配空间，并在函数返回时释放。下次函数调用时可以重用内存空间。

因为相同范围的内存地址被反复使用，栈是存储数据最高效的内存空间。几乎可以肯定的是，若没有大型数组，这部分内存将镜像到一级缓存中。所以，应该尽可能将所有变量和对象声明在使用它们的函数中。

通过在`{}`中声明变量，可以使变量的生命周期变小。但即时可以在退出`{}`时释放内存，大多数编译器在函数返回之前不会释放变量使用的内存。如果变量存储在寄存器中，则可以在函数返回前释放。

全局和静态存储

全局变量声明在函数外。任何函数都可以访问它们。全局变量存储在内存的静态部分。使用`static`修饰的变量、浮点常量、字符串常量、数组初始化列表、`switch`语句跳转表和虚函数表也都存储在静态存储区。

静态数据区通常分为三部分：

- 程序永远不会修改的常量
- 可能修改的初始化变量
- 可能修改的未初始化变量

静态数据的优点是可以在程序启动前将变量初始化为所需的值。缺点是即使仅用于程序的一小部分，仍需在整个执行过程中占用内存空间。这会降低数据缓存效率，因为内存空间不能用其它用途。

尽量避免将变量设置为全局变量。线程间通信可能需要全局变量，但这也是唯一必须使用全局变量地方。如果多个函数需要访问同一变量，但不希望将其作为参数传递，可以将变量设为全局变量。但让函数作为类的成员函数，然后访问同一个类中保存的成员变量可能是一种更好的方法。采用何种方案取决于编程风格。

最好将查找表声明为静态常量，例如：

```C++
// Example 7.1
float SomeFunction (int x) {
 static const float list[] = {1.1, 0.3, -2.0, 4.4, 2.5};
 return list[x];
}
```

这样做的好处是，不需要在每次调用时都初始化列表。静态声明有助于编译器确定边可以在下一次调用时重用。常量有助于编译器确定表从不改变。在函数中声明的初始化静态变量意味着变量必须在第一次调用时初始化。因为每次调用都需要检查是否为第一次调用，这样是低效的。`const`声明告诉编译器无需进行此项检查。一些编译器会对查找表做优化，但尽量加上`static`和`const`声明，以便在所有的编译器上都可以实现性能优化。

字符串常量和浮点常量通常存储在静态内存中，例如：

```C++
// Example 7.2
a = b * 3.5;
c = d + 3.5;
```

在这里常量3.5将存储在静态内存中。大多数编译器会认识到这两个常量是相同的，因此只需存储一个。整个程序中所有相同的常量都将被视为一种，以最大限度的减少用于常量的缓存空间。

整数常量通常包含在指令代码中。可以认为整数常量没有缓存问题。

寄存器存储

优先数量的变量可以存储在寄存器中，而非主存储器中。寄存器是CPU内部用于临时存储的一小块内存。寄存器中的变量可以非常快的被访问。所有良好优化的编译器都会自动选择函数中最常用的变量存储在寄存器中。只要变量的生命周期不重叠，寄存器可以同时存储多个变量。

局部变量特别适合寄存器存储，因此优先使用局部变量。

寄存器的数量是有限的。在32位系统中，大约有6个用于通用目的的整型寄存器，而在64位系统中有14个。

浮点变量使用不同的寄存器。在32位系统中有8个，在64位系统中有16个，在支持`AVX512`的64位下，有32个。除非支持`SSE`或更高版本的指令集，否则一些编译器难以在32位下使用浮点寄存器变量。

Volatile

`volatile`关键字说明变量可能被其他线程修改过了。编译器假设变量时钟保持之前代码中的赋值，然后基于这一假设进行优化。`volatile`关键字可以防止这种优化。例如：

```C++
// Example 7.3. Explain volatile
volatile int seconds; // incremented every second by another thread
void DelayFiveSeconds() {
 seconds = 0;
 while (seconds < 5) {
 // do nothing while seconds count to 5
 }
}
```

在这个例子中，`DelayFiveSeconds`方法会一直等待，知道其它线程将`seconds`增加到5。如果`seconds`没有被声明为`volatile`，编译器会假定循环中`seconds`一直保持为0，循环将是一个死循环。

`volatile`关键字的作用是确保变量存储在内存中，而非寄存器中，并防止对变量进行任何优化。这在测试场景下非常有用，可以避免一些表达式被优化掉。

请注意，`volatile`并不意味着原子。他不会阻止两个变量同时写入变量。如果在将`seconds`设为0的同时，有其它线程增加`seconds`，上述代码可能失效。更安全的做法是，只读取`seconds`的值，并等待该变量改变5次。

线程本地存储

大多数编译器都支持通过`thread_local`、` __thread`或`__declspec(thread)`关键字创建全局变量和静态变量的线程本地存储。这种变量在每个线程中都有一个实例。因为需要通过存储在线程环境块中的指针访问，线程本地变量是低效的。应该避免使用静态线程本地存储，使用线程栈内存代替。任何`thread function`和`thread function`中调用的函数中声明的非静态变量都存储在线程栈中。这些变量和对象在每个线程中都有一个实例。通常情况下，可以通过在`thread function`中声明变量和对象，来避免静态线程本地存储。

Far

具有分段内存的系统，例如`DOS`和16位`Windows`，允许使用关键字`far`将变量存储在`far`数据段中。`far`存储、指针和过程的效率低下。如果程序的某个段数据太多，建议使用32位、64位段更大的系统。

动态内存分配

通过使用`new`、`delete`运算符和`malloc`、`free`函数进行动态内存分配。这些操作会花费大量时间。堆内存用于内存动态分配。以随机方式分配和释放大小不同的对象时，堆内存容易变得碎片化。对管理器要花费很长时间清理不用的空间，并搜索新空间。这一活动即为垃圾收集。按顺序分配的对象不一定顺序存储在内存中，当堆内存碎片化严重的时候，它们可能分散在不同的地址。这会使得数据缓存低效。

动态内存分配也会使代码变得复杂、更易出错。程序必须保存所有已分配对象的指针，并追踪何时不再使用它们。所有分配的对象可能在任意程序流中被释放。这是内存泄漏的常见原因。更糟糕的是，可能访问已经被释放的对象。需要额外的程序逻辑来避免此类错误。

关于动态内存分配的优缺点的进一步讨论，见原文92页。

一些编程语言，例如 `Java`，对所有对象使用动态内存分配，这当然是十分低效的。

类内声明的变量

类内声明的变量按其声明顺序存储。存储类型取决于类对象如何声明。类、结构体、联合的对象可能用到上述提到的任何存储方式。除最简单的情况外，对象不能存储在寄存器中，但其数据成员可以赋值到寄存器中。

带有静态修饰符的类成员变量将存储在静态内存中，并且仅有一个实例。同一个类中的非静态成员将存储在一起。

将变量存储在类或结构体中，可以确保这些变量在内存中彼此临近。原文52页描述了使用类的优缺点。

## 7.2 整型变量和操作符

**整型大小**

如下表所示，有多种不同尺寸的整型，可以是有符号或无符号的。

| declaration                                                  | size, bits | minimum value | maximum value | in stdint.h |
| ------------------------------------------------------------ | ---------- | ------------- | ------------- | ----------- |
| `char`                                                       | 8          | -128          | 127           | `int8_t`    |
| `short int` (16位系统 `int`)                                 | 16         | -32768        | 32767         | `int16_t`   |
| `int` (16位系统 `long int`)                                  | 32         | -2^31         | 2^31-1        | `int32_t`   |
| `long long` or `int64_t` (MS 编译器`__int64`，64位Linux `long int`) | 64         | -2^63         | 2^63-1        | `int64_t`   |
| `unsigned char`                                              | 8          | 0             | 255           | `uint8_t`   |
| `unsigned short int`                                         | 16         | 0             | 65535         | `uint16_t`  |
| `unsigned int`                                               | 32         | 0             | 2^32-1        | `uint32_t`  |
| `unsigned long long` or `uint64_t`                           | 64         | 0             | 2^64-1        | `uint64_t`  |

如上表所示，不同平台可能使用不用的关键字指定整型大小。为了可移植性，建议使用标准头文件`stdint.h`或`inttypes.h`。

不管整型尺寸多大，整数运算的效率都很高。但如果尺寸超过寄存器大小，效率将不高。换句话说，如果在16位系统上使用32位整型，或在32位系统上使用64位整型，尤其是涉及乘除法时，会比较低效。

如果未指定整型尺寸(仅使用`int`声明)，编译器会自动选择最高效的类型。尺寸较小的整型（`char`和`short int`）性能稍低一些。在很多情况下，编译器会在计算时将这些类型转换为默认尺寸的整型，然后仅取低8位或16位。这种类型转换需要0~1个时钟周期。在64位系统中，只要不做除法，32位和64位整数之间的效率差异很小。

建议在大小无关紧要并且没有溢出风险的情况下（例如，简单变量、循环计数器等），使用默认尺寸整型。在大型数组中，建议使用尽量小的数据类型，以便更好的利用数据缓存。8、16、32、64以外的位效率都不高。在64位系统中，如果应用需要用到额外的位，那可以使用64位整型。

无符号类型`size_t`在32位系统中是32位的，在64位系统中是64位的。此类型一般用于表示数组大小和数组索引，以防发生溢出，即使当数组大小超过2GB时。

在考虑整数大小能否满足需求时，必须考虑中间计算是否会导致溢出。例如，在表达式`a=(b*c)/d`中，即使所有元素均小于整型最大值，但`(b*c)`仍可能造成溢出。编译器不会自动检测整型溢出。

**有符号 VS 无符号**

大多数情况下，有符号和无符号数的计算没有效率差异。但有一些特殊情况需要注意：

- 除以常量：当整型除以常量时，无符号比有符号快（见原文147页），`%`运算同理。
- 对大多数指令集来讲，有符号比无符号转换为浮点型要快。
- 两者溢出行为不同。
  - 无符号变量溢出产生小的正整数
  - 有符号变量溢出未正式定义，但一般行为是将正溢出环绕转换为负数。但编译器有可能基于溢出不会发生的假设，将溢出处理的分支优化掉。

有符号和无符号整型的转换是无成本的。这仅仅是对同一位数据进行不同解释而已。负整数转换为无符号数后，将被当作非常大的正数。

```C++
// Example 7.4. Signed and unsigned integers
int a, b;
double c;
b = (unsigned int)a / 10; // Convert to unsigned for fast division
c = a * 2.5; // Use signed when converting to double
```

在上例中，将a转换为无符号整型，以便进行更快的除法。当然，必须确保a不会是负数。最后一行`a * 2.5`后转换为double，更倾向使用有符号整型。

确保不要在`<`等比较操作中混用有符号和无符号整型，这种比较行为未定义，可能产生不期望的结果。

**整数运算**

整型操作通常是很快的。简单整数运算，例如：加减法、比较、位操作、移位操作，在大多数微处理器上只需要一个时钟周期。

乘法和除法要花费更长时间。在`Pentium 4`处理器上，需要花费11个时钟周期，在其它大多数处理器上需要3~4个时钟周期。在不同的处理器上，除法需要40~80个时钟周期。在`AMD`处理器上，整数尺寸越小，除法需要的时间就越小。这条规则不适用于`intel`处理器。指令延迟的细节在手册4中详细介绍了。在原文146~147页，介绍了如何加速乘除法操作。

**自增和自减运算**

前加`++i`和后加`i++`操作一样快。进行简单自增运算时，两者效率没有区别。例如，`for (i=0; i<n; i++)`完全等同于`for (i=0; i<n; ++i)`。

但当需要使用表达式结果时，两者的性能有一些差别。例如，`x = array[i++]`比`x = array[++i] `更高效，因为后者需要等待i的新值，将会有2个时钟周期左右的延迟。显然，如果需要将前加改为后加，需要同时调整i的初始值。

还有一种情况，前加比后加更高效。例如，`a = ++b;`中，编译器会认为在这个语句之后，a和b的值是相同的，因此两者可以使用相同的寄存器。但在`a = b++`中，两者的值是不同的，不可使用相同的寄存器。

上述自增运算的相关内容，也同样使用于自减运算。

